- Features encoder-decoder architecture
- Doesn't use LSTM, rather uses Self Attention
- Results in parallel processing and scalability
- Multimodal: can work with image/text/audio etc
- Excellent for sequential data like text
![[Attention is all you need.png]]